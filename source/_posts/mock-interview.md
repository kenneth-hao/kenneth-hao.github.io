---
title: 模拟面试.md
hide: true
date: 2024-03-26 16:43:07
tags:
excerpt:
---

## 思考

面试 就是一场自我营销
营销，关键就是突出自我的卖点，让客户（ HR/TL ）知道你的价值在哪儿

真诚是必杀技

## 优先级

优先按照简历内容准备面试
自我介绍、项目经验、简历中包含的技术点

持续深入学习面试八股文
AI 相关知识了解

## 自我介绍

面试官您好，我是郝跃文。

在此之前，我在丁香园担任技术专家。负责产品从需求分析到上线全周期的研发工作。
我的主要职责包括需求评审、技术方案的设计与评估、开发以及上线后的复盘分析。

在技术层面，我精通 Java，熟练使用 Spring 全家桶，熟悉分布式系统架构。

在丁香园，我成功领导了多个项目的架构选型和实施，优化了开发流程。

同时，我热衷于技术创新和团队合作，善长跨部门的协作沟通，确保项目顺利推进。

以上是我的个人介绍。


## 专业类

### Java

#### 线程池

##### 为什么要是使用线程池？

线程的创建和销毁是非常消耗系统资源的。
通过线程池，我们可以通过预先创建和管理线程来提高系统性能，无需在需要使用线程时，频繁创建和销毁线程。

##### 线程池的核心参数有哪些？

线程池的实现类 ThreadPoolExecutor

核心参数如下：

1. corePoolSize - 核心线程数，线程池中始终保持这个数量的线程处于活动状态
2. maximunPoolSize - 最大线程数。当工作队列已满，且当前运行的线程数小于最大线程数时，线程池会创建新的线程来处理任务。
3. keepAliveTime - 非核心线程空闲存活时间。
4. workQueue - 工作队列。

其他参数：

- threadFactory - 线程工厂，可以自定义线程名称、优先级、守护线程类型等
- handler - 拒绝策略。当工作队列已满，且已达到最大线程数时，新任务如何处理的策略。

###### 有哪些常用的工作队列吗？

###### 有哪些拒绝策略？



### 数据结构

#### List

ArrayList 动态数组，

#### BloomFilter

一种概率型数据结构，用于快速判断一个元素是否存在于一个集合中，以及在大规模数据中进行高效的查找和过滤

它基于位数组（Bit Array）和一系列的哈希函数构成

##### 优势

空间复杂度和时间复杂度非常低

##### 劣势

- 不允许更新
- 概率性存在

### 设计模式

#### 单例

#### 工厂

### JVM

### JMM

### ASYNC

#### ABA

#### 自旋锁

### Redis

#### Redis 为什么选择使用单线程

1. Redis 的性能瓶颈不在于 CPU，主要是内存和网络
2. 单线程编码更简单、易维护，不易出现并发类的问题，比如死锁、也可以避免线程上下文切换的开销

#### Redis 数据结构

全局 Hash 表、Hash 桶、Hash冲突链、rehash

String、List、Hash、Set、Sorted Set

动态字符串、双向链表、压缩列表、哈希表、跳表、整数数组

#### 缓存穿透

##### What

查询不存在的数据（eg. id=999999）

##### How

BloomFilter（存在的不一定存在，不存在的一定不存在）

#### Redis 性能优化


##### Way 

- slowlog
- 观察资源利用率，是否存在 CPU 资源过高的情况

##### 高复杂度命令

- 例如 SORT、SUNION、ZUNIONSTORE 等聚合类命令
- 使用 O（N）复杂度命令，且 N 的值非常大

##### Big Key

- 扫描 bigkey


- - key 集中过期

### MQ

#### 如何解决消息发送的一致性问题

什么是消息发送的一致性问题？
业务执行成功，那么这个操作所产生的消息就一定会发送出去
如果这个业务操作没有执行成功，那就不应该把消息发送出去

先执行数据库操作（事务）再发送消息，能最大可能保证消息的一致性
但是如果在消息发送的时候，MQ 服务重启了，就可能导致消息丢失

#### RocketMQ 会不会丢消息？ or 消息中间件是如何来保证消息可靠性的

首先说结论，
RocketMQ 会不会丢消息，取决于我们怎么使用。

一条消息从生产到被消费，一共会经历三个阶段。

生产、存储、消费。

##### 生产阶段

首先说生产阶段，生产者通过网络把消息发送给 Broker。
这里有两种发送消息的方式
一种是同步发送
一种是异步发送

如果是同步发送的话，生产者在把消息发送给 Broker 后，Broker 会返回响应的信息给生产者。
如果 Brokder 正常返回，就说明消息在生产阶段未丢失。

如果是异步发送的话，我们就需要重写回调方法，在回调方法中检查发送结果。

如果因为网络抖动导致消息发送失败的话，我们还可以设置一个合理的重试次数。

##### 存储阶段

然后，是存储阶段。
默认情况下，Broker 在接收到生产者发送的消息后，会优先把消息保存到内存中，然后立刻返回确认响应给生产者。随后，Broker 会定期把一批消息从内存异步刷入磁盘。

但是如果发送机器断电，消息还没有及时刷入磁盘，就会出现消息丢失的情况。

当然，我们可以通过修改配置中的消息保存机制为同步刷盘，来保证 Broker 端不会丢失消息。但是这会对性能有比较大的损耗。

##### 消费阶段

最后是消费阶段，
消费者从 Broker 拉取消息进行消费，然后执行相应的业务逻辑。执行成功后，会返回 CONSUME_SUCESS 的状态回执给 Broker。

如果 Broker 没有收到消费确认的响应，消费者下次还会再次拉去这条消息，进行重试。
这样就避免了消费阶段的消息丢失。

当然，这就要求我们在做消费逻辑的时候，必须要做好幂等。

Ref: [面试官再问我如何保证 RocketMQ 不丢失消息,这回我笑了！](https://www.cnblogs.com/goodAndyxublog/p/12563813.html)

#### 消息为什么会出现重复？

策略：不丢消息的优先级 > 重复投递的优先级

1. 重复发送（已发送未回执，网络抖动导致的重试）
2. 重复投递（已消费未回执）
3. 网络抖动、Broker 重启、消费者重启等导致的负载均衡 Rebalance


#### Consumer 是 Push OR Pull？


### MySQL

#### MySQL 出现高 CPU 占用如何排查

绝大多数情况，MySQL 出现高 CPU 占用都是用户线程引起的，

一般来说，排除 QPS 过高的情况，最常见的也就是慢 SQL 引起的 CPU 资源占用
比如 orderBy、groupBy、多表 JOIN、创建临时表等 CPU 密集型的 SQL 语句。

##### 慢 SQL 日志

排查慢 SQL 日志, 是否未使用索引

##### 线程列表

```sh
# 查看当前数据库连接状态
# 关注 State、Time 列的数据
# State 线程当前的执行状态、Time 线程在当前状态已执行的时间
# State：Sending Data => 线程正在读取和处理 SELECT 的行记录，发送给客户端
show full processlist
```

Ref: [MySQL 最佳实践：CPU 100%，MySQL 到底在干什么](https://cloud.tencent.com/developer/article/1677706)

### CDN 

cdn.domain.com => 回源 domain.com

### 技术类设计

准入、CUCKOO

对于提高系统稳定性，做了哪些事情？

MySQL 
- 慢 SQL 优化

监控
- 针对性优化

缓存
-

限流
- 

问题
- VO 实体

线上漏洞
- Excel 读取

## 项目类

Q：详细说明下关于提高系统稳定性，你做了哪些事情？
A：
主要有几类
1. 编码问题，比如 慢 SQL、滥用连接池、VO 过于复杂


2. 框架依赖问题，比如 Excel 读取

这个问题的背景是
    在负责丁香通业务的期间，系统经常 OOM；通过分析请求数据，发现是一个上传 Excel 的操作导致的。
    当时读取 Excel 的框架是 Apache 的 POI，出现问题的 Excel 大小只有 9 M。
    理论上读取这么小的文件，不太可能出现 OOM。

通过分析源码，发现 2007 版的 Excel 本质上是一个 zip 压缩文件。压缩文件内包含多个 xml 文件。其中有一个 SharedStrings.xml 用来存放单元格的文本数据。
而这个 Excel 中有一个产品详情的列，存放了长度很大的富文本信息。光 SharedStrings.xml 就包含上亿个字符
程序在解析 Excel 正文之前，需要先解析 sharedStrings.xml 并把所有文本内容 load 到内存中，这里也就会触发了 OOM。
想要解决这个问题，就要去重写 poi 解析 sharedStrings.xml 的部分。

通过查找资料，发现 Ali 的 easy excel 已经对解析 SharedStrings 的实现逻辑进行了重写
如果读取的文件较小，直接使用内存，如果文件较大则使用 Ehcache 保存为临时文件，然后再进行后续的处理

3. 异常流量

Q：请介绍几个你重度参与的系统设计
A：准入、数字营销平台（异构）

Q：介绍下你知道的安全问题

Q：说明下你发现并解决的系统安全漏洞

文件中心、满返

## 项目类

### 交易线

#### 秒杀是怎么设计的？

秒杀活动，核心要解决的问题是瞬时高并发的读和写，

我们从用户视角来分析，
首先，秒杀活动开始前几分钟，可能会有大量用户频繁访问秒杀商品的活动页面。

这可能会导致服务器产生大量查询操作，甚至导致我们的服务器网络带宽被挤爆。

所以，我们考虑把页面中的数据进行动静分离。
把类似商品详情信息这种静态数据放到 CDN，让客户端直接从 CDN 拉取数据就可以。
（ note: CDN 的更新问题，商品更新后，同步到 CDN 服务器刷新内容

针对商品库存信息这类动态数据，我们可以在活动开始前，提前把商品库存这类动态信息提前放到 Redis，做好缓存预热。

为了避免大量无效的秒杀请求在活动开始前就发送到后端服务器，我们可以在活动开始前把秒杀按钮置灰。

在秒杀活动开始后，可能会产生大量的并发写，而服务器资源能处理的并发是有限的。
为此，我们还需要做一些系统设计，避免同时产生不可预期的大量写请求。

这就需要我们把用户请求秒杀和下单整个流程异步化。同时让瞬时产生的大量秒杀下单请求，尽可能平滑的流入服务器进行处理。

还是以具体的秒杀场景举例说明，
当活动开始后，用户点击秒杀，客户端发起获取秒杀许可的请求，服务端收到这个请求后，把用户的秒杀请求发送到 MQ 后返回。
客户端轮询查询用户是否已成功获取到秒杀许可。
服务端以固定的速率消费用户的秒杀请求，并为用户分配秒杀许可，并把秒杀许可（Ticket）存入 Redis。

客户端获取到秒杀许可（Ticket）后，自动发起预下单请求，并把秒杀许可（Ticket）发送到服务端进行校验。

#### 秒杀活动的安全隐患

恶意锁库存（缩短订单有效时间、业务规则-限制用户下单数量、限流（用户、IP））

#### 库存是怎么设计的？

预扣减库存（冻结库存）


### TOD 数字营销平台

面向 B 端药企的服务平台，主要为药企提供一些通用的解决方案（准入、征集、专区、表单、）

## 非专业类

### 有几个 Offer

TODO

### 为什么空窗这么久

TODO

### 为什么从上家公司离职

一条腿走路，腿断了

